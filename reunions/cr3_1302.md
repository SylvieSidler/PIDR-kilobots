# Réunion n°3 du 13 février

## Utilisation des kilobots
On allume les kilobots avec le bouton rouge sur le bord. 

On peut brancher l'ordi à l'OHC (= la douchette) pour communiquer avec les robots.
Pour cela on a également besoin de la commande `kilogui` qui lance l'outil permettant de communiquer avec les robots et télécharger le programme que l'on veut exécuter en utilisant bootload > upload.
Les kilobots clignotent en bleu jusqu'à ce qu'ils aient finis de télécharger le programme à exécuter.

On peut demander aux robots d'exécuter des commandes simples : `reset`, `run`, `voltage` ou `sleep`.
`voltage` fait alumer la led de chaque robot d'une couleur indiquant le niveau de batterie du kilobot.

On peut vérifier la réactivité des robots en coupant la lumière de la douchette arrivant sur les robots aux robots avec une feuille de papier. 

Pour le debug, si on a un programme avec un `print`, il faut brancher un kilobot à l'ordinateur avec un cable. 

## :warning: 
 Attention les kilobots sont fragiles, à manipuler avec prudence et délicatesse !
Attention aussi à la surcharge pendant la charge pour éviter l'explosion de la batterie.


### Documentation Kilolib 
Les fonctions existantes sont décrites dans la doc.
Pour y accéder localement, il faut installer doxygen.
> **Windows**
> `sudo apt install doxygen`
> **MacOS**
> `brew install doxygen`

On peut maintenant suivre les étapes suivantes :
```shell
cd kilolib
make docs
open docs/html/index.html
```
La page d'acceuil de la `Kilobot Library API` va s'ouvrir sur votre navigateur internet.

### Compilation de programme à faire exécuter
Pour utiliser le programme, on le compile avec un Makefile qui produit 2 versions : 
- 1  version pour le simulateur que l'on peut faire tourner sur l'ordinateur
- 1 version `.hex` à télécharger  et qui sera utilisée pour les kilobots 

Pour compiler le fichier de configuration pour le simulateur, utiliser : `make -p config` 
Grâce au simulateur, on a un affichage pour le debug mais lancer la simulation sans l'afichage permet d'exécuter plus vite.


Exemple avec les échanges de couleurs : bien choisir des couleurs facilement distinguable.

***

## Possibilités de fonctionnalités 

### Gestion de la caméra 
On va faire un service en Python pour gérer la caméra en utilisant un pattern requête-réponse.
On n'a pas besoin d'avoir une architecture en parallèle complexe, on a juste besoin de récupérer des données. 
*Exemple :* le programme1 a besoin d'avoir la position de tous les robots, il demande à ce programme qui lui donne les informations necessaires d'après la capture caméra. 

### Calibration des robots
On peut avoir besoin de recalibrer les kilobots si la puissance n'est pas équilibrée ou que les pattes n'ont pas le même profil. On peut donc moduler les poids sur les puissance de moteurs pour recalibrer le kilobot.

### Analyse d'image
Utiliser une mire (le damier) pour vérifier si des carrés sont bien vu comme des carrés avec la caméra.
De même, il va falloir fair une calibration pour l'analyse d'image. Il s'agit de déterminer l'équivalence entre la taille d'un objet en pixels et sa taille réelle en cm (? pixel = ? cm).
Il faudra donc avoir une pièce de calibration (l'équivalent de la pièce en TNI) pour la déterminer.


##### Image stitching 
En plus des vérifications individuelles ci-dessus pour les caméras, il faut vérifier : 
- si le niveau de lumière est similaire entre les 2 caméras
- qu'il n'y ait pas de trou ou de chevauchement à la jointure de la vue des 2 caméras

#### Détection
On peut analyser les images transmises par la caméra pour détecter : 
- la présence des kilobots
- leur position dans l'arène
- la trajectoire d'un kilobot

La bibliotheque **openCV** (Python friendly), permet entre autre de faire de la détection dans une scène. La *transformée de Hough* peut être utilisée pour détecter des cercles.
On peut aussi utiliser des bibliothèques de réseaux de neurones si on en trouve.


#### AR
À partir de ce qui a été détecté, on permet d'afficher à l'utilisateur différentes informations : 
- afficher à l'écran ce que voit la caméra
- afficher la position et/ou id des kilobots
- afficher la **trajectoire** d'un robot (il n'y a pas besoin d'identification de robot avec ce programme)

Problème à résoudre **: la réalité augmentée necéssite l'identification du kilobot**.
Il faut pouvoir déterminer et afficher quel robot est lequel ? (Quel est l'id de chaque kilobot présent dans l'arène au moment de la capture)
Pour résoudre ce problème, on peut enrichir les robots : ajouter du papier ou du carton sur le kilobot pour mieux les détecter et différencier.


### Interface 

Pour l'interface on va utiliser la bibliotèque Flask de Python.
Les requêtes passsent par le GET de HTTP et la réponse est renvoyée en json.

#### /snapshot
Affichage d'une image de la caméra actuelle
[Python stream](https://docs.python.org/3/library/asyncio-stream.html) : bibliothèque simple d'utilisation utilisant openCV.

#### /status
Renvoie le status d'un kilobot en particulier (a besoin de l'id)

#### /position
Renvoie la position x,y des kilobots présnets dans l'arène

#### /positionId
Renvoie la position x,y du kilobot ayant l'Id précisé dans la requête

***
## Partie recherche : les jeux de languages
Un exemple de jeu de language : le naming game. 
Des processus/robots sont pairés 2 à 2 et emettent leur langage aux processus proche, écoutent, puis décident si ils gardent ou pas ce qu'ils ont entendu.
--> principe utilisé pour la démo de couleur

Ce qui doit émerger : 2 robots doivent donner le même mot pour une image donnée. Étude de l'émergence du langage.


Envisageable : faire en sorte que les robots n'écoutent que si le message les concerne 

***

# TODO 
- Discuter avec l'autre groupe pour échanger des infos (travail ensemble ou conseils sur ce qui fonctionne ou pas)
- lire l'article sur les jeux de langages d'un point de vue de la recherche
- faire le squelette pour répondre à des requêtes GET 
(pendant le code : utiliser le terminal et ne pas faire que des play sur l'IDE)
- lire la doc kilobot : pour téléguider les kilobots, cibler l'information sur 1 robot par son id, ...
***
# Prochaine réunion 

